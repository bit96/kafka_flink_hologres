# 实现方案文档

## 1. 概述

本文档详细说明 Kafka-Flink-Hologres 自动化工具的实现方案，包括项目结构、模块设计、关键算法和开发计划。

## 2. 项目目录结构

```
kafka_flink_hologres/
├── README.md                          # 项目说明文档
├── pyproject.toml                     # 项目配置和依赖
├── uv.lock                            # 依赖锁定文件
├── config.yaml                        # 配置文件示例
├── .env.example                       # 环境变量示例
├── .gitignore                         # Git 忽略文件
│
├── discuss/                           # 讨论和方案文档
│   ├── 01-需求文档.md
│   ├── 02-数据库设计.md
│   ├── 03-接口设计.md
│   └── 04-实现方案.md
│
├── docs/                              # 正式文档
│   ├── user_guide.md                  # 用户指南
│   └── api_reference.md               # API 参考
│
├── scripts/                           # 运行脚本
│   ├── setup.sh                       # 环境初始化脚本
│   ├── run.sh                         # 运行脚本
│   ├── test.sh                        # 测试脚本
│   └── init_database.sql              # 数据库初始化 SQL
│
├── logs/                              # 日志目录
│   └── .gitkeep
│
├── src/                               # 源代码
│   └── kafka_flink_tool/              # 主包
│       ├── __init__.py
│       ├── __main__.py                # CLI 入口
│       │
│       ├── config/                    # 配置模块
│       │   ├── __init__.py
│       │   └── manager.py             # 配置管理器
│       │
│       ├── models/                    # 数据模型
│       │   ├── __init__.py
│       │   ├── config.py              # 配置模型
│       │   ├── kafka.py               # Kafka 相关模型
│       │   ├── schema.py              # 数据结构模型
│       │   └── record.py              # SQL 记录模型
│       │
│       ├── database/                  # 数据库访问
│       │   ├── __init__.py
│       │   ├── connection.py          # 数据库连接管理
│       │   └── dao.py                 # 数据访问对象
│       │
│       ├── kafka/                     # Kafka 客户端
│       │   ├── __init__.py
│       │   └── client.py              # Kafka 客户端封装
│       │
│       ├── inference/                 # 类型推断
│       │   ├── __init__.py
│       │   └── type_inferencer.py     # 类型推断器
│       │
│       ├── generator/                 # SQL 生成
│       │   ├── __init__.py
│       │   ├── ddl_generator.py       # DDL 生成器
│       │   └── flink_sql_generator.py # Flink SQL 生成器
│       │
│       ├── service/                   # 业务服务
│       │   ├── __init__.py
│       │   └── generator_service.py   # 生成服务（主流程）
│       │
│       ├── cli/                       # 命令行接口
│       │   ├── __init__.py
│       │   ├── commands.py            # 命令定义
│       │   └── main.py                # CLI 主程序
│       │
│       └── utils/                     # 工具函数
│           ├── __init__.py
│           ├── logger.py              # 日志工具
│           └── exceptions.py          # 异常定义
│
└── tests/                             # 测试代码
    ├── __init__.py
    ├── test_config.py
    ├── test_type_inferencer.py
    ├── test_ddl_generator.py
    ├── test_flink_sql_generator.py
    └── test_service.py
```

## 3. 模块详细设计

### 3.1 配置模块 (config/)

#### 3.1.1 manager.py

**职责**：加载和管理配置

**核心功能**：
- 从 YAML 文件加载配置
- 支持环境变量替换
- 验证配置完整性

**关键类**：
```python
class ConfigManager:
    def __init__(self, config_path: str)
    def load_config(self) -> dict
    def get_hologres_config(self) -> HologresConfig
    def get_logging_config(self) -> dict
    def get_tool_config(self) -> dict
```

**代码行数估算**：~100 行

### 3.2 数据模型 (models/)

#### 3.2.1 config.py

**职责**：定义配置相关的数据模型

**关键类**：
```python
class HologresConfig(BaseModel):
    host: str
    port: int
    database: str
    user: str
    password: str

class PoolConfig(BaseModel):
    min_size: int
    max_size: int
    timeout: int
```

**代码行数估算**：~80 行

#### 3.2.2 kafka.py

**职责**：定义 Kafka 相关的数据模型

**关键类**：
```python
class KafkaTopicConfig(BaseModel):
    id: int
    topic_name: str
    kafka_brokers: str
    kafka_group_id: Optional[str]
    kafka_security_protocol: Optional[str]
    kafka_sasl_mechanism: Optional[str]
    kafka_sasl_username: Optional[str]
    kafka_sasl_password: Optional[str]
    data_format: str
    description: Optional[str]
    is_active: bool
```

**代码行数估算**：~60 行

#### 3.2.3 schema.py

**职责**：定义数据结构模型

**关键类**：
```python
class FieldSchema(BaseModel):
    name: str
    type: str
    nullable: bool
    sample_values: List[Any]

class InferredSchema(BaseModel):
    fields: List[FieldSchema]
    sample_data_count: int
    inference_time: str
```

**代码行数估算**：~50 行

#### 3.2.4 record.py

**职责**：定义 SQL 记录模型

**关键类**：
```python
class FlinkSQLRecord(BaseModel):
    id: Optional[int]
    topic_id: int
    topic_name: str
    sink_table_name: str
    source_ddl: str
    sink_ddl: str
    insert_sql: str
    full_sql: str
    field_mapping: Optional[dict]
    inferred_schema: Optional[dict]
    sample_count: int
    status: str
    error_message: Optional[str]
    created_by: Optional[str]
```

**代码行数估算**：~80 行

### 3.3 数据库访问 (database/)

#### 3.3.1 connection.py

**职责**：管理数据库连接

**核心功能**：
- 创建数据库连接池
- 提供上下文管理器
- 连接健康检查

**关键类**：
```python
class DatabaseConnection:
    def __init__(self, config: HologresConfig)
    def get_connection(self)
    def close(self)
    def __enter__(self)
    def __exit__(self)
```

**代码行数估算**：~120 行

#### 3.3.2 dao.py

**职责**：数据访问对象，封装所有数据库操作

**核心功能**：
- CRUD 操作
- 查询 Topic 配置
- 保存 SQL 记录
- 表管理

**关键类**：
```python
class HologresDAO:
    def __init__(self, connection: DatabaseConnection)

    # Topic 配置相关
    def get_topic_config_by_id(self, topic_id: int) -> Optional[KafkaTopicConfig]
    def get_topic_config_by_name(self, topic_name: str) -> Optional[KafkaTopicConfig]

    # 表管理相关
    def table_exists(self, table_name: str) -> bool
    def create_table(self, ddl: str) -> None
    def drop_table(self, table_name: str) -> None

    # SQL 记录相关
    def save_flink_sql_record(self, record: FlinkSQLRecord) -> int
    def list_flink_sql_records(self, ...) -> List[FlinkSQLRecord]
    def get_flink_sql_record(self, record_id: int) -> Optional[FlinkSQLRecord]
```

**代码行数估算**：~250 行

### 3.4 Kafka 客户端 (kafka/)

#### 3.4.1 client.py

**职责**：封装 Kafka 客户端操作

**核心功能**：
- 连接 Kafka
- 采样消息
- 处理认证
- 解析 JSON 消息

**关键类**：
```python
class KafkaClient:
    def __init__(self, config: KafkaTopicConfig)
    def connect(self) -> None
    def sample_messages(self, count: int) -> List[Dict[str, Any]]
    def close(self) -> None
    def __enter__(self)
    def __exit__(self)
```

**代码行数估算**：~180 行

### 3.5 类型推断 (inference/)

#### 3.5.1 type_inferencer.py

**职责**：推断数据类型

**核心功能**：
- 分析字段值
- 推断字段类型
- 应用宽松类型策略
- 处理类型冲突

**关键类**：
```python
class TypeInferencer:
    def __init__(self, use_loose_types: bool = True)

    def infer_schema(self, messages: List[Dict[str, Any]]) -> InferredSchema
    def infer_field_type(self, values: List[Any]) -> str

    # 内部辅助方法
    def _collect_fields(self, messages: List[Dict]) -> Dict[str, List[Any]]
    def _infer_python_type(self, value: Any) -> str
    def _resolve_type_conflict(self, types: List[str]) -> str
    def _map_to_sql_type(self, python_type: str) -> str
```

**代码行数估算**：~200 行

**关键算法**：

1. **字段收集算法**：
```python
def _collect_fields(messages):
    field_values = defaultdict(list)
    for msg in messages:
        for key, value in msg.items():
            field_values[key].append(value)
    return field_values
```

2. **类型推断算法**：
```python
def infer_field_type(values):
    # 1. 收集所有非 None 值的类型
    types = [type(v) for v in values if v is not None]

    # 2. 统计各类型出现次数
    type_counts = Counter(types)

    # 3. 应用宽松类型策略
    if int in types and float in types:
        return "DOUBLE"
    elif any(t in [int, float] for t in types) and str in types:
        return "TEXT"

    # 4. 返回最常见的类型
    return most_common_type
```

### 3.6 SQL 生成 (generator/)

#### 3.6.1 ddl_generator.py

**职责**：生成 Hologres DDL

**核心功能**：
- 生成 CREATE TABLE 语句
- 添加字段注释
- 格式化 SQL

**关键类**：
```python
class DDLGenerator:
    def generate_hologres_ddl(
        self,
        table_name: str,
        schema: InferredSchema
    ) -> str

    def _format_field_definition(self, field: FieldSchema) -> str
    def _generate_comments(self, table_name: str, schema: InferredSchema) -> str
```

**代码行数估算**：~120 行

**DDL 模板**：
```sql
CREATE TABLE IF NOT EXISTS {table_name} (
    {field1} {type1} {nullable1},
    {field2} {type2} {nullable2},
    ...
);

COMMENT ON TABLE {table_name} IS '{comment}';
COMMENT ON COLUMN {table_name}.{field1} IS '{field_comment}';
```

#### 3.6.2 flink_sql_generator.py

**职责**：生成 Flink SQL

**核心功能**：
- 生成 Source 表 DDL
- 生成 Sink 表 DDL
- 生成 INSERT 语句
- 组装完整 SQL

**关键类**：
```python
class FlinkSQLGenerator:
    def generate_source_ddl(
        self,
        table_name: str,
        schema: InferredSchema,
        kafka_config: KafkaTopicConfig
    ) -> str

    def generate_sink_ddl(
        self,
        table_name: str,
        schema: InferredSchema,
        hologres_config: HologresConfig
    ) -> str

    def generate_insert_sql(
        self,
        source_table: str,
        sink_table: str,
        schema: InferredSchema
    ) -> str

    def generate_full_sql(
        self,
        source_ddl: str,
        sink_ddl: str,
        insert_sql: str
    ) -> str
```

**代码行数估算**：~280 行

**Flink SQL 模板**：

1. **Source 表模板**：
```sql
CREATE TABLE kafka_source_{topic_name} (
    {field_definitions}
) WITH (
    'connector' = 'kafka',
    'topic' = '{topic_name}',
    'properties.bootstrap.servers' = '{brokers}',
    'properties.group.id' = '{group_id}',
    'format' = 'json',
    'scan.startup.mode' = 'latest-offset'
);
```

2. **Sink 表模板**：
```sql
CREATE TABLE hologres_sink_{table_name} (
    {field_definitions}
) WITH (
    'connector' = 'hologres',
    'dbname' = '{database}',
    'tablename' = '{table_name}',
    'username' = '{user}',
    'password' = '{password}',
    'endpoint' = '{host}:{port}'
);
```

3. **INSERT 语句模板**：
```sql
INSERT INTO hologres_sink_{table_name}
SELECT {field_list}
FROM kafka_source_{topic_name};
```

### 3.7 业务服务 (service/)

#### 3.7.1 generator_service.py

**职责**：主流程编排

**核心功能**：
- 编排整个生成流程
- 协调各个模块
- 错误处理
- 事务管理

**关键类**：
```python
class FlinkSQLGeneratorService:
    def __init__(self, config_path: str = "config.yaml")

    def generate(
        self,
        topic_id: Optional[int] = None,
        topic_name: Optional[str] = None,
        sink_table: Optional[str] = None,
        create_mode: str = "create",
        sample_count: int = 10
    ) -> int

    # 内部流程方法
    def _load_topic_config(self, topic_id, topic_name) -> KafkaTopicConfig
    def _sample_data(self, kafka_config, sample_count) -> List[Dict]
    def _infer_schema(self, messages) -> InferredSchema
    def _generate_ddls(self, schema, configs) -> Tuple[str, str, str, str]
    def _manage_table(self, table_name, ddl, create_mode) -> None
    def _save_record(self, record_data) -> int
```

**代码行数估算**：~280 行

**主流程伪代码**：
```python
def generate(topic_id, topic_name, sink_table, create_mode, sample_count):
    # 1. 加载配置
    config = load_config()
    topic_config = get_topic_config(topic_id, topic_name)

    # 2. 采样数据
    kafka_client = KafkaClient(topic_config)
    messages = kafka_client.sample_messages(sample_count)

    # 3. 推断类型
    inferencer = TypeInferencer()
    schema = inferencer.infer_schema(messages)

    # 4. 生成 DDL
    ddl_gen = DDLGenerator()
    hologres_ddl = ddl_gen.generate_hologres_ddl(sink_table, schema)

    # 5. 生成 Flink SQL
    flink_gen = FlinkSQLGenerator()
    source_ddl = flink_gen.generate_source_ddl(...)
    sink_ddl = flink_gen.generate_sink_ddl(...)
    insert_sql = flink_gen.generate_insert_sql(...)
    full_sql = flink_gen.generate_full_sql(...)

    # 6. 管理表
    dao = HologresDAO(connection)
    if create_mode == "overwrite" and dao.table_exists(sink_table):
        dao.drop_table(sink_table)
    if not dao.table_exists(sink_table):
        dao.create_table(hologres_ddl)

    # 7. 保存记录
    record = FlinkSQLRecord(...)
    record_id = dao.save_flink_sql_record(record)

    return record_id
```

### 3.8 命令行接口 (cli/)

#### 3.8.1 commands.py

**职责**：定义 CLI 命令

**核心功能**：
- 定义命令参数
- 参数验证
- 调用业务服务

**代码行数估算**：~150 行

#### 3.8.2 main.py

**职责**：CLI 入口

**核心功能**：
- 解析命令行参数
- 路由到对应命令
- 异常处理

**代码行数估算**：~100 行

### 3.9 工具模块 (utils/)

#### 3.9.1 logger.py

**职责**：日志配置

**核心功能**：
- 配置日志格式
- 配置日志输出
- 日志轮转

**代码行数估算**：~80 行

#### 3.9.2 exceptions.py

**职责**：异常定义

**核心功能**：
- 定义自定义异常
- 异常错误码

**代码行数估算**：~60 行

## 4. 依赖管理

### 4.1 pyproject.toml

```toml
[project]
name = "kafka-flink-tool"
version = "0.1.0"
description = "Kafka to Flink to Hologres automation tool"
requires-python = ">=3.11"
dependencies = [
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "kafka-python>=2.0.0",
    "psycopg2-binary>=2.9.0",
    "click>=8.0.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "mypy>=1.0.0",
    "ruff>=0.1.0",
]

[tool.uv]
dev-dependencies = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "mypy>=1.0.0",
    "ruff>=0.1.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

## 5. 开发计划

### 5.1 第一阶段：项目初始化（0.5 天）

**任务**：
1. 创建项目目录结构
2. 配置 pyproject.toml
3. 初始化 uv 虚拟环境
4. 创建配置文件模板
5. 编写数据库初始化脚本
6. 编写运行脚本

**交付物**：
- 完整的项目结构
- `scripts/setup.sh`
- `scripts/init_database.sql`
- `config.yaml.example`

### 5.2 第二阶段：基础模块开发（1 天）

**任务**：
1. 实现数据模型 (models/)
2. 实现配置管理 (config/)
3. 实现日志工具 (utils/logger.py)
4. 实现异常定义 (utils/exceptions.py)

**交付物**：
- 所有数据模型类
- ConfigManager
- 日志配置
- 异常类

### 5.3 第三阶段：数据访问层（1 天）

**任务**：
1. 实现数据库连接管理 (database/connection.py)
2. 实现 DAO (database/dao.py)
3. 实现 Kafka 客户端 (kafka/client.py)
4. 编写单元测试

**交付物**：
- DatabaseConnection
- HologresDAO
- KafkaClient
- 测试用例

### 5.4 第四阶段：核心业务逻辑（1.5 天）

**任务**：
1. 实现类型推断器 (inference/type_inferencer.py)
2. 实现 DDL 生成器 (generator/ddl_generator.py)
3. 实现 Flink SQL 生成器 (generator/flink_sql_generator.py)
4. 编写单元测试

**交付物**：
- TypeInferencer
- DDLGenerator
- FlinkSQLGenerator
- 测试用例

### 5.5 第五阶段：服务编排和 CLI（1 天）

**任务**：
1. 实现生成服务 (service/generator_service.py)
2. 实现 CLI 命令 (cli/)
3. 集成测试
4. Bug 修复

**交付物**：
- FlinkSQLGeneratorService
- CLI 接口
- 集成测试

### 5.6 第六阶段：文档和交付（0.5 天）

**任务**：
1. 编写 README
2. 编写用户指南
3. 代码审查
4. 最终测试

**交付物**：
- README.md
- docs/user_guide.md
- 可运行的完整项目

**总计：5.5 天**

## 6. 代码规范

### 6.1 命名规范

- **模块名**：小写字母，下划线分隔（如 `type_inferencer.py`）
- **类名**：大驼峰（如 `TypeInferencer`）
- **函数/方法名**：小写字母，下划线分隔（如 `infer_schema`）
- **常量**：全大写，下划线分隔（如 `DEFAULT_SAMPLE_COUNT`）
- **私有方法**：前缀下划线（如 `_internal_method`）

### 6.2 类型注解

所有函数必须包含类型注解：

```python
def sample_messages(self, count: int = 10) -> List[Dict[str, Any]]:
    pass
```

### 6.3 文档字符串

使用 Google 风格的文档字符串：

```python
def infer_schema(self, messages: List[Dict[str, Any]]) -> InferredSchema:
    """推断数据结构。

    Args:
        messages: JSON 消息列表

    Returns:
        推断的数据结构

    Raises:
        ValueError: 如果消息列表为空
    """
    pass
```

### 6.4 代码行数限制

- 每个 Python 文件不超过 300 行
- 每个函数不超过 50 行
- 每行代码不超过 100 字符

## 7. 测试策略

### 7.1 单元测试

- 覆盖所有核心模块
- 测试覆盖率 > 80%
- 使用 pytest

### 7.2 集成测试

- 端到端流程测试
- Mock Kafka 和 Hologres

### 7.3 测试数据

准备测试用的：
- 示例 Kafka 消息
- 示例配置
- 预期输出

## 8. 风险和应对

### 8.1 技术风险

| 风险 | 影响 | 概率 | 应对措施 |
|------|------|------|---------|
| Kafka 连接不稳定 | 高 | 中 | 增加重试机制 |
| 类型推断不准确 | 中 | 中 | 提供手动调整接口 |
| Hologres 兼容性问题 | 高 | 低 | 充分测试 |
| 依赖库版本冲突 | 低 | 低 | 使用 uv 锁定版本 |

### 8.2 进度风险

| 风险 | 影响 | 概率 | 应对措施 |
|------|------|------|---------|
| 需求变更 | 中 | 中 | 模块化设计，易于调整 |
| 开发延期 | 中 | 低 | 预留缓冲时间 |

## 9. 后续优化方向

### 9.1 性能优化

- 并行采样多个 Topic
- 缓存 Topic 配置
- 优化数据库查询

### 9.2 功能增强

- 支持嵌套 JSON
- 支持 Avro 格式
- 支持更多 Sink 类型
- Web UI 界面

### 9.3 运维增强

- 健康检查接口
- 监控指标输出
- 告警机制

## 10. 附录

### 10.1 关键算法复杂度分析

| 算法 | 时间复杂度 | 空间复杂度 |
|------|-----------|-----------|
| 字段收集 | O(n*m) | O(n*m) |
| 类型推断 | O(n*m) | O(m) |
| DDL 生成 | O(m) | O(m) |
| SQL 生成 | O(m) | O(m) |

其中：
- n = 采样消息数量
- m = 字段数量

### 10.2 性能基准

基于 10 条样本数据，20 个字段的场景：

| 阶段 | 预期耗时 |
|------|---------|
| 数据采样 | < 5 秒 |
| 类型推断 | < 1 秒 |
| DDL 生成 | < 0.5 秒 |
| SQL 生成 | < 0.5 秒 |
| 表创建 | < 2 秒 |
| SQL 保存 | < 1 秒 |
| **总计** | **< 10 秒** |
