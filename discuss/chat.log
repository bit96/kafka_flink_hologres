æˆ‘ä»”ç»†å®¡æŸ¥äº†ä¿®æ­£ç‰ˆå®žçŽ°æ–¹æ¡ˆæ–‡æ¡£ï¼Œå‘çŽ°è¿˜æœ‰ä»¥ä¸‹é—®é¢˜éœ€è¦æ³¨æ„ï¼š

  ðŸ”´ å‘çŽ°çš„æ–°é—®é¢˜

  1. ç±»åž‹æŽ¨æ–­é€»è¾‘ç¼ºé™·ï¼ˆtype_inference.py ç¬¬ 365-366 è¡Œï¼‰

  elif 'bool' in types and len(types) == 1:
      return 'BOOLEAN'

  é—®é¢˜ï¼šJSON ä¸­çš„å¸ƒå°”å€¼åœ¨ Python ä¸­ä¼šè¢«è¯†åˆ«ä¸º bool ç±»åž‹ï¼Œä½†åŒæ—¶ä¹Ÿä¼šæ»¡è¶³å…¶ä»–æ¡ä»¶ã€‚æ›´ä¸¥é‡çš„é—®é¢˜æ˜¯ï¼šåœ¨ Python ä¸­ï¼Œbool æ˜¯ int çš„å­ç±»ï¼Œæ‰€ä»¥ isinstance(True, int) è¿”å›ž Trueï¼

  è¿™æ„å‘³ç€ï¼š
  - å¦‚æžœå­—æ®µå€¼æ˜¯ [True, False, True]ï¼Œtype(True).__name__ ä¼šæ˜¯ 'bool'
  - ä½†æ˜¯ bool ç»§æ‰¿è‡ª intï¼Œæ‰€ä»¥ç±»åž‹åˆ¤æ–­å¯èƒ½å‡ºçŽ°æ··æ·†

  å»ºè®®æ”¹è¿›ï¼š
  # åº”è¯¥å…ˆæ£€æŸ¥ boolï¼Œå› ä¸º bool æ˜¯ int çš„å­ç±»
  if 'bool' in types and len(types) == 1:
      return 'BOOLEAN'
  elif 'float' in types or 'int' in types:
      # å¦‚æžœåŒæ—¶æœ‰ bool å’Œ intï¼Œè¯´æ˜Žæœ‰éžå¸ƒå°”çš„æ•´æ•°
      if 'float' in types:
          return 'DOUBLE'
      elif 'bool' not in types:  # åªæœ‰çº¯æ•´æ•°æ‰åˆ¤å®šä¸º BIGINT
          return 'BIGINT'
      else:
          return 'TEXT'  # bool + int æ··åˆï¼Œé™çº§ä¸º TEXT

  ---
  2. å­—æ®µé¡ºåºä¸ç¡®å®šæ€§é—®é¢˜ï¼ˆtype_inference.py ç¬¬ 329-332 è¡Œï¼‰

  field_values = defaultdict(list)
  for msg in messages:
      for key, value in msg.items():
          field_values[key].append(value)

  é—®é¢˜ï¼š
  - ä½¿ç”¨ dict.items() éåŽ†ï¼Œåœ¨ Python 3.7+ è™½ç„¶ä¿æŒæ’å…¥é¡ºåºï¼Œä½†ä¸åŒæ¶ˆæ¯çš„å­—æ®µé¡ºåºå¯èƒ½ä¸åŒ
  - ç”Ÿæˆçš„ DDL å’Œ Flink SQL å­—æ®µé¡ºåºå¯èƒ½ä¸Žç”¨æˆ·æœŸæœ›ä¸ä¸€è‡´

  å»ºè®®æ”¹è¿›ï¼š
  # æ–¹æ¡ˆ 1ï¼šæŒ‰å­—æ®µåæŽ’åº
  fields.sort(key=lambda f: f.name)

  # æ–¹æ¡ˆ 2ï¼šæŒ‰ç¬¬ä¸€æ¡æ¶ˆæ¯çš„å­—æ®µé¡ºåº
  first_message_keys = list(messages[0].keys()) if messages else []
  fields.sort(key=lambda f: first_message_keys.index(f.name) if f.name in first_message_keys else 999)

  ---
  3. é…ç½®æ–‡ä»¶ç¼ºå°‘ç¤ºä¾‹ï¼ˆç¬¬ 6 ç« ç¼ºå¤±ï¼‰

  æ–‡æ¡£ä¸­æåˆ° "åˆ›å»º config.yaml é…ç½®æ–‡ä»¶"ï¼Œä½†æ²¡æœ‰æä¾›é…ç½®æ–‡ä»¶çš„å®Œæ•´ç¤ºä¾‹ã€‚

  å»ºè®®è¡¥å……ï¼š
  # config.yaml ç¤ºä¾‹
  hologres:
    host: "hologres-cn-hangzhou.aliyuncs.com"
    port: 80
    database: "my_database"
    user: "my_user"
    password: "my_password"

  ---
  4. ç¼ºå°‘ scripts/run.sh çš„å®žçŽ°ï¼ˆç¬¬ 24-26 è¡Œï¼‰

  ç›®å½•ç»“æž„ä¸­æåˆ° scripts/run.shï¼Œä½†æ²¡æœ‰è¯´æ˜Žå…¶å†…å®¹ã€‚

  å»ºè®®è¡¥å……ï¼š
  #!/bin/bash
  # scripts/run.sh

  # æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
  source .venv/bin/activate

  # è¿è¡Œå·¥å…·
  python -m kafka_flink_tool "$@"

  ---
  5. ç¼ºå°‘ .gitignore å†…å®¹ï¼ˆç¬¬ 16 è¡Œï¼‰

  æåˆ°äº† .gitignore æ–‡ä»¶ï¼Œä½†æ²¡æœ‰è¯´æ˜Žå†…å®¹ã€‚

  å»ºè®®è¡¥å……ï¼š
  # .gitignore
  .venv/
  __pycache__/
  *.pyc
  *.pyo
  *.pyd
  .Python
  *.so
  *.egg
  *.egg-info/
  dist/
  build/
  logs/*.log
  config.yaml
  .DS_Store
  .idea/
  .vscode/

  ---
  6. type_inference.py ä¸­çš„å¼‚å¸¸å¤„ç†è¿‡äºŽå®½æ³›ï¼ˆç¬¬ 389-394 è¡Œï¼‰

  for fmt in timestamp_formats:
      try:
          datetime.strptime(value, fmt)
          return True
      except:  # âŒ è£¸ exceptï¼Œæ•èŽ·æ‰€æœ‰å¼‚å¸¸
          continue
  return False

  é—®é¢˜ï¼šä½¿ç”¨è£¸ except ä¼šæ•èŽ·æ‰€æœ‰å¼‚å¸¸ï¼ŒåŒ…æ‹¬ KeyboardInterruptã€SystemExit ç­‰

  å»ºè®®æ”¹è¿›ï¼š
  except (ValueError, TypeError):
      continue

  ---
  7. Kafka Consumer æ²¡æœ‰æŒ‡å®š group_idï¼ˆkafka_client.py ç¬¬ 281-288 è¡Œï¼‰

  consumer = KafkaConsumer(
      self.topic_name,
      bootstrap_servers=self.brokers,
      auto_offset_reset='earliest',
      enable_auto_commit=False,
      consumer_timeout_ms=30000,
      value_deserializer=lambda m: json.loads(m.decode('utf-8'))
  )

  é—®é¢˜ï¼š
  - æ²¡æœ‰æŒ‡å®š group_idï¼ŒKafka ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªéšæœºçš„ group_id
  - æ¯æ¬¡è¿è¡Œéƒ½ä¼šä»Žå¤´å¼€å§‹è¯»å–ï¼ˆå› ä¸ºæ˜¯æ–°çš„ consumer groupï¼‰
  - å¦‚æžœ Topic æ•°æ®é‡å¤§ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜

  å»ºè®®æ”¹è¿›ï¼š
  import uuid

  consumer = KafkaConsumer(
      self.topic_name,
      bootstrap_servers=self.brokers,
      group_id=f'kafka_flink_tool_{uuid.uuid4().hex[:8]}',  # æ¯æ¬¡ç”Ÿæˆå”¯ä¸€ group_id
      auto_offset_reset='earliest',
      enable_auto_commit=False,
      consumer_timeout_ms=30000,
      value_deserializer=lambda m: json.loads(m.decode('utf-8'))
  )

  ---
  8. JSON è§£æžå¤±è´¥æ²¡æœ‰å¤„ç†ï¼ˆkafka_client.py ç¬¬ 287 è¡Œï¼‰

  value_deserializer=lambda m: json.loads(m.decode('utf-8'))

  é—®é¢˜ï¼šå¦‚æžœ Kafka æ¶ˆæ¯ä¸æ˜¯åˆæ³•çš„ JSONï¼Œä¼šæŠ›å‡ºå¼‚å¸¸å¯¼è‡´æ•´ä¸ªé‡‡æ ·å¤±è´¥

  å»ºè®®æ”¹è¿›ï¼š
  def safe_json_deserializer(m):
      try:
          return json.loads(m.decode('utf-8'))
      except (json.JSONDecodeError, UnicodeDecodeError) as e:
          logger.warning(f"JSON è§£æžå¤±è´¥ï¼Œè·³è¿‡è¯¥æ¶ˆæ¯: {e}")
          return None  # è¿”å›ž None è¡¨ç¤ºè·³è¿‡

  # ç„¶åŽåœ¨é‡‡æ ·æ—¶è¿‡æ»¤æŽ‰ None
  messages = [msg for msg in raw_messages if msg is not None]

  ---
  9. ç¼ºå°‘ init.py çš„å†…å®¹è¯´æ˜Žï¼ˆç¬¬ 35 è¡Œï¼‰

  __init__.py æ²¡æœ‰è¯´æ˜Žæ˜¯å¦éœ€è¦å¯¼å‡ºå†…å®¹ã€‚

  å»ºè®®è¡¥å……ï¼š
  # src/kafka_flink_tool/__init__.py
  """Kafka-Flink-Hologres è‡ªåŠ¨åŒ–å·¥å…·"""

  __version__ = "0.1.0"

  ---
  10. ä¾èµ–ç‰ˆæœ¬å¯èƒ½è¿‡äºŽå®½æ¾ï¼ˆç¬¬ 745-750 è¡Œï¼‰

  dependencies = [
      "pydantic>=2.0.0",  # å¯èƒ½åŒ…å«ä¸å…¼å®¹çš„ 3.x ç‰ˆæœ¬
      "pyyaml>=6.0",
      "kafka-python>=2.0.0",
      ...
  ]

  å»ºè®®æ”¹è¿›ï¼š
  dependencies = [
      "pydantic>=2.0.0,<3.0.0",  # é™åˆ¶ä¸»ç‰ˆæœ¬
      "pyyaml>=6.0,<7.0",
      "kafka-python>=2.0.0,<3.0.0",
      "psycopg2-binary>=2.9.0,<3.0.0",
      "click>=8.0.0,<9.0.0",
  ]

  ---
  ðŸ“Š é—®é¢˜æ±‡æ€»

  | é—®é¢˜                   | ä¸¥é‡æ€§  | å½±å“         |
  |----------------------|------|------------|
  | 1. bool/int ç±»åž‹æ··æ·†     | ðŸ”´ é«˜ | å¯èƒ½å¯¼è‡´ç±»åž‹æŽ¨æ–­é”™è¯¯ |
  | 2. å­—æ®µé¡ºåºä¸ç¡®å®š           | ðŸŸ¡ ä¸­ | å½±å“ç”¨æˆ·ä½“éªŒ     |
  | 3. ç¼ºå°‘ config.yaml ç¤ºä¾‹ | ðŸŸ¡ ä¸­ | é™ä½Žå¯ç”¨æ€§      |
  | 4. ç¼ºå°‘ run.sh å®žçŽ°      | ðŸŸ¡ ä¸­ | é™ä½Žå¯ç”¨æ€§      |
  | 5. ç¼ºå°‘ .gitignore å†…å®¹  | ðŸŸ¢ ä½Ž | å¯èƒ½è¯¯æäº¤æ•æ„Ÿæ–‡ä»¶  |
  | 6. è£¸ except è¯­å¥       | ðŸŸ¡ ä¸­ | å¯èƒ½æ•èŽ·æ„å¤–å¼‚å¸¸   |
  | 7. ç¼ºå°‘ group_id       | ðŸŸ¡ ä¸­ | æ€§èƒ½å’Œè¡Œä¸ºä¸å¯æŽ§   |
  | 8. JSON è§£æžå¤±è´¥æœªå¤„ç†      | ðŸ”´ é«˜ | å¯èƒ½å¯¼è‡´ç¨‹åºå´©æºƒ   |
  | 9. ç¼ºå°‘ init.py å†…å®¹     | ðŸŸ¢ ä½Ž | é™ä½Žä»£ç è§„èŒƒæ€§    |
  | 10. ä¾èµ–ç‰ˆæœ¬è¿‡äºŽå®½æ¾         | ðŸŸ¡ ä¸­ | å¯èƒ½å¼•å…¥ä¸å…¼å®¹ç‰ˆæœ¬  |

  ---
  âœ… å»ºè®®çš„ä¿®æ­£è®¡åˆ’

  æˆ‘å»ºè®®åˆ›å»ºä¸€ä¸ªæœ€ç»ˆä¿®æ­£ç‰ˆï¼Œè§£å†³ä»¥ä¸Š 10 ä¸ªé—®é¢˜ï¼ŒåŒ…æ‹¬ï¼š

  1. ä¿®å¤ç±»åž‹æŽ¨æ–­çš„ bool/int æ··æ·†é—®é¢˜
  2. ä¿è¯å­—æ®µé¡ºåºçš„ä¸€è‡´æ€§
  3. è¡¥å…… config.yaml ç¤ºä¾‹
  4. è¡¥å…… scripts/run.sh å®žçŽ°
  5. è¡¥å…… .gitignore å†…å®¹
  6. æ”¹è¿›å¼‚å¸¸å¤„ç†
  7. ä¸º Kafka Consumer æ·»åŠ  group_id
  8. å¤„ç† JSON è§£æžå¤±è´¥çš„æƒ…å†µ
  9. è¡¥å…… init.py å†…å®¹
  10. é™åˆ¶ä¾èµ–ç‰ˆæœ¬èŒƒå›´

  ä½ å¸Œæœ›æˆ‘åˆ›å»ºæœ€ç»ˆä¿®æ­£ç‰ˆæ–‡æ¡£å—ï¼Ÿ

